{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML System Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Level Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a high level overview. The system design goes as the following. The system recieves a location fix, then sends uses the foursquare api to recieve the venue list. It also grabs relevant metadata about the location fix, and aggregates the venue list and metadata for it's prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"SystemDesign.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GIS DataBase and Embedding\n",
    "The GIS Database and Rastorization and Loc2VecEmbedding is spoken about in this blog post (https://www.sentiance.com/2018/05/03/venue-mapping/)\n",
    "To create the relevant metadata, the GIS Database could be  a local copy of OpenStreetMap stored in a PostGis database. PostGis is a convenient PostgreSQL extension that adds support for spatial operators, types and indices.\n",
    "This PostGresDataBase will help us get metadata about the location other than just the venues. As well, creating the rastorization and image to go through loc2vec model. This will give us a rich embedding of the information of the location.\n",
    "\n",
    "\n",
    "## Kafka\n",
    "\n",
    "Apache Kafka is a very popular tool to process streams of data. The data is naturally will be in a more streaming like fashion as the user is constantly sending locations fixes. The KafkaProducer does alot of the heavy lifting.\n",
    "Firstly, it recieves a location fix and then connects to the PostGres database to find the relevant GIS data and the image needed to feed the Loc2Vec ML algorithm. The Loc2Vec ML algorithm will then return an embedding. The producer will also call the FourSquareAPI to get the candidates. Both the embedding and candidates will be fed into another Kafka Topic, which will recieve the pair of data that will be input for our ML Algorithm. After which, Kafka will send the relevant location information into another PostGresDataBase.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
